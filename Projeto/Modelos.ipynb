{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto de Férias - Aprendizado de Máquina\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predição de emissão de gases em um dataset sobre turbinas \n",
    "\n",
    "**Aluno:** Enzo J. Xavier - RM 24035\n",
    "\n",
    "**Orientador:** Dr. Daniel Roberto Cassar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relembrar: Explicar notebook anterior, referenciar link \n",
    "\n",
    "Explicar: Falar objetivo do notebook atual, passo a passo\n",
    "\n",
    "Modelar: Abordar os modelos usados, teoria e fórmula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importações e definições:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as principais bibliotecas usadas neste notebok. A documentação de cada biblioteca se encontra no final do arquivo, na sessão \"Referências\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "\n",
    "import lightning as L\n",
    "import darts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TempDataset(Dataset):\n",
    "    \"\"\"Ajuda a criar um dataset com os batches de treinamento\"\"\"\n",
    "    def __init__(self, sequencias):\n",
    "        self.sequencias = sequencias\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequencias)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequencia, target = self.sequencias[idx]\n",
    "        return torch.FloatTensor(sequencia), torch.FloatTensor(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(L.LightningDataModule):\n",
    "    \"\"\"Módulo padrão para lidar com todas as etapas do dataset, facilitando a organização\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ATRIBUTOS = ['AT','AP','AH','AFDP','GTEP','TIT','TAT','TEY','CDP']  # Define ATRIBUTOS here\n",
    "        self.TARGET = ['CO', 'NOX']  # Define TARGET here\n",
    "        self.TAMANHO_SEQUENCIA = 20\n",
    "        #TAMANHO_SEQUENCIA = 20\n",
    "        self.TAMANHO_LOTE = 128\n",
    "        self.definicoes()\n",
    "        self.pre_processing()  \n",
    "\n",
    "    def definicoes(self):\n",
    "            # Diretório\n",
    "            atual = os.getcwd()\n",
    "            caminho = os.path.dirname(atual)\n",
    "            os.chdir(f'{caminho}\\\\Datasets')\n",
    "\n",
    "            # Carregar datasets\n",
    "            df_2011 = pd.read_csv('gt_2011.csv')\n",
    "            df_2012 = pd.read_csv('gt_2012.csv')\n",
    "            df_2013 = pd.read_csv('gt_2013.csv')\n",
    "            df_2014 = pd.read_csv('gt_2014.csv')\n",
    "            df_2015 = pd.read_csv('gt_2015.csv')\n",
    "\n",
    "            # Dividir datasets\n",
    "            self.df_treino = pd.concat([df_2011,df_2012], ignore_index= True)\n",
    "            self.df_val = df_2013\n",
    "            self.df_teste = pd.concat([df_2014,df_2015], ignore_index= True)\n",
    "            self.df_tot = pd.concat([df_2011,df_2012,df_2013,df_2014,df_2015], ignore_index= True)\n",
    "\n",
    "    def pre_processing(self):\n",
    "            # Organizar e normalizar dados\n",
    "            self.X_treino = self.df_treino.reindex(self.ATRIBUTOS, axis=1).values\n",
    "            self.y_treino = self.df_treino.reindex(self.TARGET, axis=1).values\n",
    "\n",
    "            self.x_scaler = StandardScaler()\n",
    "            self.x_scaler.fit(self.X_treino)\n",
    "            self.y_scaler = StandardScaler() # não vou ajustar pro y - vazar dados. \n",
    "            self.y_scaler.fit(self.y_treino)                                 # só criar modelo e transformar funciona?\n",
    "\n",
    "    def setup(self, stage):\n",
    "        \"\"\"Aqui devemos alterar o estado da classe para adicionar as informações \n",
    "        referentes aos conjuntos de treino, teste e validação. O argumento `stage` \n",
    "        deve existir e ele indica em qual estágio o processo de treino está \n",
    "        (pode ser `fit` para treinamento/validação e `test` para teste).\n",
    "\n",
    "        É nesta etapa onde aplicamos transformações aos dados caso necessário.\"\"\"\n",
    "\n",
    "        def cria_sequencias(self, data_x, data_y, tamanho_sequencia):\n",
    "            '''Divide o dataset em exemplos (batches) para o treinamento do LSTM'''\n",
    "            sequencias = []\n",
    "\n",
    "            for i in range(len(data_x) - tamanho_sequencia):\n",
    "                sequencia_x = data_x[i : i + tamanho_sequencia]\n",
    "                target_y = data_y[i + tamanho_sequencia]\n",
    "                sequencias.append((sequencia_x, target_y))\n",
    "\n",
    "            return sequencias\n",
    "\n",
    "        # Controlar modo de operação\n",
    "        if stage == \"fit\":\n",
    "            # Treino\n",
    "            self.X_treino_norm = self.x_scaler.transform(self.X_treino)\n",
    "            self.y_treino_norm = self.y_scaler.transform(self.y_treino)\n",
    "            \n",
    "            self.seq_treino = cria_sequencias(self = self, data=self.X_treino_norm, tamanho_sequencia=self.TAMANHO_SEQUENCIA)\n",
    "            self.X_treino_norm = torch.tensor(self.X_treino_norm, dtype=torch.float32)\n",
    "            self.y_treino_norm = torch.tensor(self.y_treino_norm, dtype=torch.float32)\n",
    "\n",
    "            # Validação\n",
    "            self.X_val = self.df_val.reindex(self.ATRIBUTOS, axis=1).values\n",
    "            self.y_val = self.df_val.reindex(self.TARGET, axis=1).values\n",
    "            self.X_val_norm = self.x_scaler.transform(X_val)\n",
    "            self.y_val_norm = self.y_scaler.transform(y_val)\n",
    "            \n",
    "            self.seq_val = cria_sequencias(self.X_val_norm, self.TAMANHO_SEQUENCIA)\n",
    "            self.X_val_norm = torch.tensor(self.X_val_norm, dtype=torch.float32)\n",
    "            self.y_val_norm = torch.tensor(self.y_val_norm, dtype=torch.float32)\n",
    "        if stage == \"test\":\n",
    "            # Teste\n",
    "            self.X_teste = self.df_teste.reindex(self.ATRIBUTOS, axis=1).values\n",
    "            self.y_teste = self.df_teste.reindex(self.TARGET, axis=1).values\n",
    "\n",
    "            X_teste_norm = self.x_scaler.transform(X_teste)\n",
    "            y_teste_norm = self.y_scaler.transform(y_teste)\n",
    "\n",
    "            self.seq_teste = cria_sequencias(self.X_teste_norm, self.TAMANHO_SEQUENCIA)\n",
    "            self.X_teste_norm = torch.tensor(self.X_teste_norm, dtype=torch.float32)\n",
    "            self.y_teste_norm = torch.tensor(self.y_teste_norm, dtype=torch.float32)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        self.dataset_treino = TempDataset(self.seq_treino)\n",
    "        self.dataloader_treino = DataLoader(\n",
    "            self.dataset_treino, batch_size=self.TAMANHO_LOTE, shuffle=False)\n",
    "        return self.dataloader_treino\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        self.dataset_val = TempDataset(self.seq_val)\n",
    "        self.dataloader_val = DataLoader(\n",
    "            self.dataset_val, batch_size=self.TAMANHO_LOTE, shuffle=False)\n",
    "        return self.dataloader_val\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        self.dataset_teste = TempDataset(self.seq_teste)\n",
    "        self.dataloader_teste = DataLoader(\n",
    "            self.dataset_teste, batch_size=self.TAMANHO_LOTE, shuffle=False)\n",
    "        return self.dataloader_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Darts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesModel(L.LightningModule):\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = torch.nn.LSTM(num_inputs, num_hidden, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(num_hidden, num_outputs) # function\n",
    "        self.loss = F.mse_loss\n",
    "\n",
    "        # Curva de aprendizado\n",
    "        self.perdas_treino = []\n",
    "        self.perdas_val = []\n",
    "\n",
    "        self.curva_aprendizado_treino = []\n",
    "        self.curva_aprendizado_val = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        return self.fc(hidden[-1])\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.01)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = self.loss(y, y_pred)\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.perdas_treino.append(loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = self.loss(y, y_pred)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.perdas_val.append(loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = self.loss(y, y_pred)\n",
    "\n",
    "        self.log(\"test_loss\", loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        # Atualiza curva de aprendizado treino\n",
    "        perda_media = torch.stack(self.perdas_treino).mean()\n",
    "        self.curva_aprendizado_treino.append(float(perda_media))\n",
    "        self.perdas_treino.clear()\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Atualiza curva de aprendizado validação\n",
    "        perda_media = torch.stack(self.perdas_val).mean()\n",
    "        self.curva_aprendizado_val.append(float(perda_media))\n",
    "        self.perdas_val.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCAS = 5\n",
    "treinador = L.Trainer(max_epochs=NUM_EPOCAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stage = \"fit\" \n",
    "#ATRIBUTOS = ['AT','AP','AH','AFDP','GTEP','TIT','TAT','TEY','CDP']\n",
    "#TARGET = ['CO', 'NOX']\n",
    "\n",
    "\n",
    "dm = DataModule()\n",
    "#dm.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = len(ATRIBUTOS)\n",
    "num_hidden = 1\n",
    "num_outputs = len(TARGET)\n",
    "#taxa_aprendizado = 0.01\n",
    "\n",
    "modelo = TimeSeriesModel(\n",
    "    num_inputs, num_hidden, num_outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.TAMANHO_LOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'CO' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\enzo24035\\OneDrive - ILUM ESCOLA DE CIÊNCIA\\Documentos\\Outros\\Estágios\\Enzo-Januzzi---Redes-Neurais\\Projeto\\Modelos.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m treinador\u001b[39m.\u001b[39;49mfit(modelo, dm)\n",
      "File \u001b[1;32mc:\\venv\\ilumpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m TrainerStatus\u001b[39m.\u001b[39mRUNNING\n\u001b[0;32m    543\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 544\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[0;32m    545\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[0;32m    546\u001b[0m )\n",
      "File \u001b[1;32mc:\\venv\\ilumpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 44\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32mc:\\venv\\ilumpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    574\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    575\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[0;32m    576\u001b[0m     ckpt_path,\n\u001b[0;32m    577\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    578\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    579\u001b[0m )\n\u001b[1;32m--> 580\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[0;32m    582\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[0;32m    583\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\venv\\ilumpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:950\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39msetup_environment()\n\u001b[0;32m    948\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__setup_profiler()\n\u001b[1;32m--> 950\u001b[0m call\u001b[39m.\u001b[39;49m_call_setup_hook(\u001b[39mself\u001b[39;49m)  \u001b[39m# allow user to setup lightning_module in accelerator environment\u001b[39;00m\n\u001b[0;32m    952\u001b[0m \u001b[39m# check if we should delay restoring checkpoint till later\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mrestore_checkpoint_after_setup:\n",
      "File \u001b[1;32mc:\\venv\\ilumpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:92\u001b[0m, in \u001b[0;36m_call_setup_hook\u001b[1;34m(trainer)\u001b[0m\n\u001b[0;32m     89\u001b[0m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mbarrier(\u001b[39m\"\u001b[39m\u001b[39mpre_setup\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mdatamodule \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m     _call_lightning_datamodule_hook(trainer, \u001b[39m\"\u001b[39;49m\u001b[39msetup\u001b[39;49m\u001b[39m\"\u001b[39;49m, stage\u001b[39m=\u001b[39;49mfn)\n\u001b[0;32m     93\u001b[0m _call_callback_hooks(trainer, \u001b[39m\"\u001b[39m\u001b[39msetup\u001b[39m\u001b[39m\"\u001b[39m, stage\u001b[39m=\u001b[39mfn)\n\u001b[0;32m     94\u001b[0m _call_lightning_module_hook(trainer, \u001b[39m\"\u001b[39m\u001b[39msetup\u001b[39m\u001b[39m\"\u001b[39m, stage\u001b[39m=\u001b[39mfn)\n",
      "File \u001b[1;32mc:\\venv\\ilumpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:179\u001b[0m, in \u001b[0;36m_call_lightning_datamodule_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(fn):\n\u001b[0;32m    178\u001b[0m     \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningDataModule]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mdatamodule\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 179\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    180\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\enzo24035\\OneDrive - ILUM ESCOLA DE CIÊNCIA\\Documentos\\Outros\\Estágios\\Enzo-Januzzi---Redes-Neurais\\Projeto\\Modelos.ipynb Cell 22\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X26sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_treino_norm \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_scaler\u001b[39m.\u001b[39mtransform(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_treino)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X26sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_treino_norm \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_scaler\u001b[39m.\u001b[39mtransform(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_treino)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X26sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseq_treino \u001b[39m=\u001b[39m cria_sequencias(\u001b[39mself\u001b[39;49m \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m, data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX_treino_norm, tamanho_sequencia\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mTAMANHO_SEQUENCIA)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X26sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_treino_norm \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_treino_norm, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X26sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_treino_norm \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_treino_norm, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n",
      "\u001b[1;32mc:\\Users\\enzo24035\\OneDrive - ILUM ESCOLA DE CIÊNCIA\\Documentos\\Outros\\Estágios\\Enzo-Januzzi---Redes-Neurais\\Projeto\\Modelos.ipynb Cell 22\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X26sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(data) \u001b[39m-\u001b[39m tamanho_sequencia):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X26sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     sequencia \u001b[39m=\u001b[39m data[i : i \u001b[39m+\u001b[39m tamanho_sequencia]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X26sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     target \u001b[39m=\u001b[39m data[i \u001b[39m+\u001b[39m tamanho_sequencia, [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mATRIBUTOS\u001b[39m.\u001b[39;49mindex(col) \u001b[39mfor\u001b[39;49;00m col \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mTARGET]]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X26sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     sequencias\u001b[39m.\u001b[39mappend((sequencia, target))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X26sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39mreturn\u001b[39;00m sequencias\n",
      "\u001b[1;32mc:\\Users\\enzo24035\\OneDrive - ILUM ESCOLA DE CIÊNCIA\\Documentos\\Outros\\Estágios\\Enzo-Januzzi---Redes-Neurais\\Projeto\\Modelos.ipynb Cell 22\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X26sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(data) \u001b[39m-\u001b[39m tamanho_sequencia):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X26sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     sequencia \u001b[39m=\u001b[39m data[i : i \u001b[39m+\u001b[39m tamanho_sequencia]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X26sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     target \u001b[39m=\u001b[39m data[i \u001b[39m+\u001b[39m tamanho_sequencia, [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mATRIBUTOS\u001b[39m.\u001b[39;49mindex(col) \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mTARGET]]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X26sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     sequencias\u001b[39m.\u001b[39mappend((sequencia, target))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X26sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39mreturn\u001b[39;00m sequencias\n",
      "\u001b[1;31mValueError\u001b[0m: 'CO' is not in list"
     ]
    }
   ],
   "source": [
    "treinador.fit(modelo, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x shape: torch.Size([128, 20, 9])\n",
    "y shape: torch.Size([128, 9])\n",
    "y_pred shape: torch.Size([128, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_treino = modelo.curva_aprendizado_treino\n",
    "ca_val = modelo.curva_aprendizado_val\n",
    "\n",
    "sns.lineplot(ca_treino, label=\"Treino\")\n",
    "eixo = sns.lineplot(ca_val, label=\"Validação\")\n",
    "\n",
    "eixo.set_xlim(left=0)\n",
    "\n",
    "eixo.set_title(\"Curva de aprendizado\")\n",
    "eixo.set_xlabel(\"Época\")\n",
    "eixo.set_ylabel(\"Loss\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1]\n",
    "\n",
    "[2]\n",
    "\n",
    "[3]\n",
    "\n",
    "[4]\n",
    "\n",
    "[] Biblioteca do normalizador padrão - scikit learn: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "\n",
    "[] David Menotti, aula sobre MLP: https://www.inf.ufpr.br/menotti/ci171-182/slides/ci171-classMLP.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy",
   "language": "python",
   "name": "ilumpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
