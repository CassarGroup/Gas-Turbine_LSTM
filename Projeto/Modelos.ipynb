{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto de Férias - Aprendizado de Máquina\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predição de emissão de gases em um dataset sobre turbinas \n",
    "\n",
    "**Aluno:** Enzo J. Xavier - RM 24035\n",
    "\n",
    "**Orientador:** Dr. Daniel Roberto Cassar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relembrar: Explicar notebook anterior, referenciar link \n",
    "\n",
    "Explicar: Falar objetivo do notebook atual, passo a passo\n",
    "\n",
    "Modelar: Abordar os modelos usados, teoria e fórmula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importações e definições:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as principais bibliotecas usadas neste notebok. A documentação de cada biblioteca se encontra no final do arquivo, na sessão \"Referências\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "\n",
    "import lightning as L\n",
    "import darts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAMANHO_LOTE = 128\n",
    "\n",
    "class TempDataset(Dataset):\n",
    "    \"\"\"Ajuda a criar um dataset com os batches de treinamento\"\"\"\n",
    "    def __init__(self, sequencias):\n",
    "        self.sequencias = sequencias\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequencias)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequencia, target = self.sequencias[idx]\n",
    "        return torch.FloatTensor(sequencia), torch.FloatTensor(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(L.LightningDataModule):\n",
    "    \"\"\"Módulo padrão para lidar com todas as etapas do dataset, facilitando a organização\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ATRIBUTOS = ['AT','AP','AH','AFDP','GTEP','TIT','TAT','TEY','CDP']  # Define ATRIBUTOS here\n",
    "        self.TARGET = ['CO', 'NOX']  # Define TARGET here\n",
    "        self.TAMANHO_SEQUENCIA = 20\n",
    "        self.definicoes()\n",
    "        self.pre_processing()  \n",
    "\n",
    "    def definicoes(self):\n",
    "            # Diretório\n",
    "            atual = os.getcwd()\n",
    "            caminho = os.path.dirname(atual)\n",
    "            os.chdir(f'{caminho}\\\\Datasets')\n",
    "\n",
    "            # Carregar datasets\n",
    "            df_2011 = pd.read_csv('gt_2011.csv')\n",
    "            df_2012 = pd.read_csv('gt_2012.csv')\n",
    "            df_2013 = pd.read_csv('gt_2013.csv')\n",
    "            df_2014 = pd.read_csv('gt_2014.csv')\n",
    "            df_2015 = pd.read_csv('gt_2015.csv')\n",
    "\n",
    "            # Dividir datasets\n",
    "            df_treino = pd.concat([df_2011,df_2012], ignore_index= True)\n",
    "            df_val = df_2013\n",
    "            df_teste = pd.concat([df_2014,df_2015], ignore_index= True)\n",
    "            df_tot = pd.concat([df_2011,df_2012,df_2013,df_2014,df_2015], ignore_index= True)\n",
    "\n",
    "    def pre_processing(self):\n",
    "            # Organizar e normalizar dados\n",
    "            X_treino = df_treino.reindex(self.ATRIBUTOS, axis=1).values\n",
    "            y_treino = df_treino.reindex(self.TARGET, axis=1).values\n",
    "\n",
    "            self.x_scaler = StandardScaler()\n",
    "            self.x_scaler.fit(X_treino)\n",
    "            self.y_scaler = StandardScaler() # não vou ajustar pro y - vazar dados. \n",
    "            self.y_scaler.fit(y_treino)                                 # só criar modelo e transformar funciona?\n",
    "\n",
    "    def setup(self, stage):\n",
    "        \"\"\"Aqui devemos alterar o estado da classe para adicionar as informações \n",
    "        referentes aos conjuntos de treino, teste e validação. O argumento `stage` \n",
    "        deve existir e ele indica em qual estágio o processo de treino está \n",
    "        (pode ser `fit` para treinamento/validação e `test` para teste).\n",
    "\n",
    "        É nesta etapa onde aplicamos transformações aos dados caso necessário.\"\"\"\n",
    "\n",
    "        def cria_sequencias(data, tamanho_sequencia):\n",
    "            '''Divide o dataset em exemplos (batches) para o treinamento do LSTM'''\n",
    "            sequencias = []\n",
    "\n",
    "            for i in range(len(data) - tamanho_sequencia):\n",
    "                sequencia = data[i : i + tamanho_sequencia]\n",
    "                target = data[i + tamanho_sequencia]\n",
    "                sequencias.append((sequencia, target))\n",
    "\n",
    "            return sequencias\n",
    "\n",
    "        # Controlar modo de operação\n",
    "        if stage == \"fit\":\n",
    "            # Treino\n",
    "            X_treino_norm = self.x_scaler.transform(X_treino)\n",
    "            y_treino_norm = self.y_scaler.transform(y_treino)\n",
    "            \n",
    "            self.seq_treino = cria_sequencias(X_treino_norm, TAMANHO_SEQUENCIA)\n",
    "            self.X_treino_norm = torch.tensor(X_treino_norm, dtype=torch.float32)\n",
    "            self.y_treino_norm = torch.tensor(y_treino_norm, dtype=torch.float32)\n",
    "\n",
    "            # Validação\n",
    "            X_val = df_val.reindex(self.ATRIBUTOS, axis=1).values\n",
    "            y_val = df_val.reindex(self.TARGET, axis=1).values\n",
    "            X_val_norm = self.x_scaler.transform(X_val)\n",
    "            y_val_norm = self.y_scaler.transform(y_val)\n",
    "            \n",
    "            self.seq_val = cria_sequencias(X_val_norm, TAMANHO_SEQUENCIA)\n",
    "            self.X_val_norm = torch.tensor(X_val_norm, dtype=torch.float32)\n",
    "            self.y_val_norm = torch.tensor(y_val_norm, dtype=torch.float32)\n",
    "        if stage == \"test\":\n",
    "            # Teste\n",
    "            X_teste = df_teste.reindex(self.ATRIBUTOS, axis=1).values\n",
    "            y_teste = df_teste.reindex(self.TARGET, axis=1).values\n",
    "\n",
    "            X_teste_norm = self.x_scaler.transform(X_teste)\n",
    "            y_teste_norm = self.y_scaler.transform(y_teste)\n",
    "\n",
    "            self.seq_teste = cria_sequencias(X_teste_norm, TAMANHO_SEQUENCIA)\n",
    "            self.X_teste_norm = torch.tensor(X_teste_norm, dtype=torch.float32)\n",
    "            self.y_teste_norm = torch.tensor(y_teste_norm, dtype=torch.float32)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset_treino = TempDataset(self.seq_treino)\n",
    "        dataloader_treino = DataLoader(\n",
    "            dataset_treino, batch_size=TAMANHO_LOTE, shuffle=False)\n",
    "        return dataloader_treino\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset_val = TempDataset(self.seq_val)\n",
    "        dataloader_val = DataLoader(\n",
    "            dataset_val, batch_size=TAMANHO_LOTE, shuffle=False)\n",
    "        return dataloader_val\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        dataset_teste = TempDataset(self.seq_teste)\n",
    "        dataloader_teste = DataLoader(\n",
    "            dataset_teste, batch_size=TAMANHO_LOTE, shuffle=False)\n",
    "        return dataloader_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Darts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesModel(L.LightningModule):\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = torch.nn.LSTM(num_inputs, num_hidden, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(num_hidden, num_outputs) # function\n",
    "        self.loss = F.mse_loss\n",
    "\n",
    "        # Curva de aprendizado\n",
    "        self.perdas_treino = []\n",
    "        self.perdas_val = []\n",
    "\n",
    "        self.curva_aprendizado_treino = []\n",
    "        self.curva_aprendizado_val = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        return self.fc(hidden[-1])\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.01)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = self.loss(y, y_pred)\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.perdas_treino.append(loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = self.loss(y, y_pred)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.perdas_val.append(loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = self.loss(y, y_pred)\n",
    "\n",
    "        self.log(\"test_loss\", loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        # Atualiza curva de aprendizado treino\n",
    "        perda_media = torch.stack(self.perdas_treino).mean()\n",
    "        self.curva_aprendizado_treino.append(float(perda_media))\n",
    "        self.perdas_treino.clear()\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Atualiza curva de aprendizado validação\n",
    "        perda_media = torch.stack(self.perdas_val).mean()\n",
    "        self.curva_aprendizado_val.append(float(perda_media))\n",
    "        self.perdas_val.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCAS = 5\n",
    "treinador = L.Trainer(max_epochs=NUM_EPOCAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_treino' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\enzo24035\\OneDrive - ILUM ESCOLA DE CIÊNCIA\\Documentos\\Outros\\Estágios\\Enzo-Januzzi---Redes-Neurais\\Projeto\\Modelos.ipynb Cell 19\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#stage = \"fit\" \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#ATRIBUTOS = ['AT','AP','AH','AFDP','GTEP','TIT','TAT','TEY','CDP']\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#TARGET = ['CO', 'NOX']\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m dm \u001b[39m=\u001b[39m DataModule()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#dm.setup('fit')\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\enzo24035\\OneDrive - ILUM ESCOLA DE CIÊNCIA\\Documentos\\Outros\\Estágios\\Enzo-Januzzi---Redes-Neurais\\Projeto\\Modelos.ipynb Cell 19\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mTAMANHO_SEQUENCIA \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefinicoes()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X24sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpre_processing()\n",
      "\u001b[1;32mc:\\Users\\enzo24035\\OneDrive - ILUM ESCOLA DE CIÊNCIA\\Documentos\\Outros\\Estágios\\Enzo-Januzzi---Redes-Neurais\\Projeto\\Modelos.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X24sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpre_processing\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X24sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m         \u001b[39m# Organizar e normalizar dados\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X24sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         X_treino \u001b[39m=\u001b[39m df_treino\u001b[39m.\u001b[39mreindex(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mATRIBUTOS, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mvalues\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X24sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         y_treino \u001b[39m=\u001b[39m df_treino\u001b[39m.\u001b[39mreindex(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mTARGET, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mvalues\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X24sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_scaler \u001b[39m=\u001b[39m StandardScaler()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_treino' is not defined"
     ]
    }
   ],
   "source": [
    "#stage = \"fit\" \n",
    "#ATRIBUTOS = ['AT','AP','AH','AFDP','GTEP','TIT','TAT','TEY','CDP']\n",
    "#TARGET = ['CO', 'NOX']\n",
    "\n",
    "\n",
    "dm = DataModule()\n",
    "#dm.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = len(ATRIBUTOS)\n",
    "num_hidden = 1\n",
    "num_outputs = len(TARGET)\n",
    "#taxa_aprendizado = 0.01\n",
    "\n",
    "modelo = TimeSeriesModel(\n",
    "    num_inputs, num_hidden, num_outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataModule' object has no attribute 'x_scaler'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\enzo24035\\OneDrive - ILUM ESCOLA DE CIÊNCIA\\Documentos\\Outros\\Estágios\\Enzo-Januzzi---Redes-Neurais\\Projeto\\Modelos.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m treinador\u001b[39m.\u001b[39;49mfit(modelo, dm)\n",
      "File \u001b[1;32mc:\\venv\\ilumpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m TrainerStatus\u001b[39m.\u001b[39mRUNNING\n\u001b[0;32m    543\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 544\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[0;32m    545\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[0;32m    546\u001b[0m )\n",
      "File \u001b[1;32mc:\\venv\\ilumpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 44\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32mc:\\venv\\ilumpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    574\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    575\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[0;32m    576\u001b[0m     ckpt_path,\n\u001b[0;32m    577\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    578\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    579\u001b[0m )\n\u001b[1;32m--> 580\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[0;32m    582\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[0;32m    583\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\venv\\ilumpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:950\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39msetup_environment()\n\u001b[0;32m    948\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__setup_profiler()\n\u001b[1;32m--> 950\u001b[0m call\u001b[39m.\u001b[39;49m_call_setup_hook(\u001b[39mself\u001b[39;49m)  \u001b[39m# allow user to setup lightning_module in accelerator environment\u001b[39;00m\n\u001b[0;32m    952\u001b[0m \u001b[39m# check if we should delay restoring checkpoint till later\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mrestore_checkpoint_after_setup:\n",
      "File \u001b[1;32mc:\\venv\\ilumpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:92\u001b[0m, in \u001b[0;36m_call_setup_hook\u001b[1;34m(trainer)\u001b[0m\n\u001b[0;32m     89\u001b[0m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mbarrier(\u001b[39m\"\u001b[39m\u001b[39mpre_setup\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mdatamodule \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m     _call_lightning_datamodule_hook(trainer, \u001b[39m\"\u001b[39;49m\u001b[39msetup\u001b[39;49m\u001b[39m\"\u001b[39;49m, stage\u001b[39m=\u001b[39;49mfn)\n\u001b[0;32m     93\u001b[0m _call_callback_hooks(trainer, \u001b[39m\"\u001b[39m\u001b[39msetup\u001b[39m\u001b[39m\"\u001b[39m, stage\u001b[39m=\u001b[39mfn)\n\u001b[0;32m     94\u001b[0m _call_lightning_module_hook(trainer, \u001b[39m\"\u001b[39m\u001b[39msetup\u001b[39m\u001b[39m\"\u001b[39m, stage\u001b[39m=\u001b[39mfn)\n",
      "File \u001b[1;32mc:\\venv\\ilumpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:179\u001b[0m, in \u001b[0;36m_call_lightning_datamodule_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(fn):\n\u001b[0;32m    178\u001b[0m     \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningDataModule]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mdatamodule\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 179\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    180\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\enzo24035\\OneDrive - ILUM ESCOLA DE CIÊNCIA\\Documentos\\Outros\\Estágios\\Enzo-Januzzi---Redes-Neurais\\Projeto\\Modelos.ipynb Cell 21\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X26sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m# Controlar modo de operação\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X26sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mif\u001b[39;00m stage \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X26sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     \u001b[39m# Treino\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X26sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     X_treino_norm \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx_scaler\u001b[39m.\u001b[39mtransform(X_treino)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X26sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     y_treino_norm \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_scaler\u001b[39m.\u001b[39mtransform(y_treino)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X26sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseq_treino \u001b[39m=\u001b[39m cria_sequencias(X_treino_norm, TAMANHO_SEQUENCIA)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataModule' object has no attribute 'x_scaler'"
     ]
    }
   ],
   "source": [
    "treinador.fit(modelo, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x shape: torch.Size([128, 20, 9])\n",
    "y shape: torch.Size([128, 9])\n",
    "y_pred shape: torch.Size([128, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_treino = modelo.curva_aprendizado_treino\n",
    "ca_val = modelo.curva_aprendizado_val\n",
    "\n",
    "sns.lineplot(ca_treino, label=\"Treino\")\n",
    "eixo = sns.lineplot(ca_val, label=\"Validação\")\n",
    "\n",
    "eixo.set_xlim(left=0)\n",
    "\n",
    "eixo.set_title(\"Curva de aprendizado\")\n",
    "eixo.set_xlabel(\"Época\")\n",
    "eixo.set_ylabel(\"Loss\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1]\n",
    "\n",
    "[2]\n",
    "\n",
    "[3]\n",
    "\n",
    "[4]\n",
    "\n",
    "[] Biblioteca do normalizador padrão - scikit learn: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "\n",
    "[] David Menotti, aula sobre MLP: https://www.inf.ufpr.br/menotti/ci171-182/slides/ci171-classMLP.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy",
   "language": "python",
   "name": "ilumpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
