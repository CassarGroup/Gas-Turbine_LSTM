{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto de Férias - Aprendizado de Máquina\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predição de emissão de gases em um dataset sobre turbinas \n",
    "\n",
    "**Aluno:** Enzo J. Xavier - RM 24035\n",
    "\n",
    "**Orientador:** Dr. Daniel Roberto Cassar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relembrar: Explicar notebook anterior, referenciar link \n",
    "\n",
    "Explicar: Falar objetivo do notebook atual, passo a passo\n",
    "\n",
    "Modelar: Abordar os modelos usados, teoria e fórmula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importações e definições:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as principais bibliotecas usadas neste notebok. A documentação de cada biblioteca se encontra no final do arquivo, na sessão \"Referências\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "\n",
    "import lightning as L\n",
    "import darts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAMANHO_LOTE = 128\n",
    "\n",
    "class TempDataset(Dataset):\n",
    "    def __init__(self, sequencias):\n",
    "        self.sequencias = sequencias\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequencias)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequencia, target = self.sequencias[idx]\n",
    "        return torch.FloatTensor(sequencia), torch.FloatTensor(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(L.LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def setup(self, stage):\n",
    "        \"\"\"Aqui devemos alterar o estado da classe para adicionar as informações \n",
    "        referentes aos conjuntos de treino, teste e validação. O argumento `stage` \n",
    "        deve existir e ele indica em qual estágio o processo de treino está \n",
    "        (pode ser `fit` para treinamento/validação e `test` para teste).\n",
    "\n",
    "        É nesta etapa onde aplicamos transformações aos dados caso necessário.\"\"\"\n",
    "\n",
    "        # Diretório\n",
    "        atual = os.getcwd()\n",
    "        caminho = os.path.dirname(atual)\n",
    "        os.chdir(f'{caminho}\\\\Datasets')\n",
    "        \n",
    "        # Definições\n",
    "        ATRIBUTOS = ['AT','AP','AH','AFDP','GTEP','TIT','TAT','TEY','CDP']\n",
    "        TARGET = ['CO', 'NOX']\n",
    "        TAMANHO_SEQUENCIA = 20 # a cada 20 horas\n",
    "\n",
    "        # Carregar datasets\n",
    "        df_2011 = pd.read_csv('gt_2011.csv')\n",
    "        df_2012 = pd.read_csv('gt_2012.csv')\n",
    "        df_2013 = pd.read_csv('gt_2013.csv')\n",
    "        df_2014 = pd.read_csv('gt_2014.csv')\n",
    "        df_2015 = pd.read_csv('gt_2015.csv')\n",
    "\n",
    "        # Dividir datasets\n",
    "        df_treino = pd.concat([df_2011,df_2012], ignore_index= True)\n",
    "        df_val = df_2013\n",
    "        df_teste = pd.concat([df_2014,df_2015], ignore_index= True)\n",
    "        df_tot = pd.concat([df_2011,df_2012,df_2013,df_2014,df_2015], ignore_index= True)\n",
    "\n",
    "        # Organizar e normalizar dados\n",
    "        X_treino = df_treino.reindex(ATRIBUTOS, axis=1).values\n",
    "        y_treino = df_treino.reindex(TARGET, axis=1).values\n",
    "\n",
    "        self.x_scaler = StandardScaler()\n",
    "        self.x_scaler.fit(X_treino)\n",
    "        #self.y_scaler = StandardScaler() # não vou ajustar pro y - vazar dados. \n",
    "                                         # só criar modelo e transformar funciona?\n",
    "\n",
    "        # Criar batches\n",
    "        def cria_sequencias(data, tamanho_sequencia):\n",
    "            '''Divide o dataset em exemplos (batches) para o treinamento do LSTM'''\n",
    "            sequencias = []\n",
    "\n",
    "            for i in range(len(data) - tamanho_sequencia):\n",
    "                sequencia = data[i : i + tamanho_sequencia]\n",
    "                target = data[i + tamanho_sequencia]\n",
    "                sequencias.append((sequencia, target))\n",
    "\n",
    "            return sequencias\n",
    "\n",
    "        # Controlar modo de operação\n",
    "        if stage == \"fit\":\n",
    "            # Treino\n",
    "            X_treino_norm = self.x_scaler.transform(X_treino)\n",
    "            #y_treino_norm = self.y_scaler.transform(y_treino)\n",
    "            seq_treino = cria_sequencias(X_treino_norm, TAMANHO_SEQUENCIA)\n",
    "\n",
    "            self.X_treino_norm = torch.tensor(X_treino_norm, dtype=torch.float32)\n",
    "            self.y_treino = torch.tensor(y_treino, dtype=torch.float32)\n",
    "\n",
    "            # Validação\n",
    "            X_val = df_val.reindex(ATRIBUTOS, axis=1).values\n",
    "            y_val = df_val.reindex(TARGET, axis=1).values\n",
    "            X_val_norm = self.x_scaler.transform(X_val)\n",
    "            #y_val_norm = self.y_scaler.transform(y_val)\n",
    "            seq_val = cria_sequencias(X_val_norm, TAMANHO_SEQUENCIA)\n",
    "\n",
    "            self.X_val_norm = torch.tensor(X_val_norm, dtype=torch.float32)\n",
    "            self.y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "        if stage == \"test\":\n",
    "            # Teste\n",
    "            X_teste = df_teste.reindex(ATRIBUTOS, axis=1).values\n",
    "            y_teste = df_teste.reindex(TARGET, axis=1).values\n",
    "\n",
    "            X_teste_norm = self.x_scaler.transform(X_teste)\n",
    "            #y_teste_norm = self.y_scaler.transform(y_teste)\n",
    "\n",
    "            seq_teste = cria_sequencias(X_teste_norm, TAMANHO_SEQUENCIA)\n",
    "\n",
    "            self.X_teste_norm = torch.tensor(X_teste_norm, dtype=torch.float32)\n",
    "            self.y_teste = torch.tensor(y_teste, dtype=torch.float32)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset_treino = TempDataset(seq_treino)\n",
    "        dataloader_treino = DataLoader(\n",
    "            dataset_treino, batch_size=TAMANHO_LOTE, shuffle=False)\n",
    "        return dataloader_treino\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset_val = TempDataset(seq_val)\n",
    "        dataloader_val = DataLoader(\n",
    "            dataset_val, batch_size=TAMANHO_LOTE, shuffle=False)\n",
    "        return dataloader_val\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        dataset_teste = TempDataset(seq_teste)\n",
    "        dataloader_teste = DataLoader(\n",
    "            dataset_teste, batch_size=TAMANHO_LOTE, shuffle=False)\n",
    "        return dataloader_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Darts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesModel(L.LightningModule):\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = torch.nn.LSTM(num_inputs, num_hidden, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(num_hidden, num_outputs) # function\n",
    "        self.loss = F.mse_loss\n",
    "\n",
    "        # Curva de aprendizado\n",
    "        self.perdas_treino = []\n",
    "        self.perdas_val = []\n",
    "\n",
    "        self.curva_aprendizado_treino = []\n",
    "        self.curva_aprendizado_val = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        return self.fc(hidden[-1])\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.01)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = self.loss(y, y_pred)\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.perdas_treino.append(loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = self.loss(y, y_pred)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.perdas_val.append(loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = self.loss(y, y_pred)\n",
    "\n",
    "        self.log(\"test_loss\", loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        # Atualiza curva de aprendizado treino\n",
    "        perda_media = torch.stack(self.perdas_treino).mean()\n",
    "        self.curva_aprendizado_treino.append(float(perda_media))\n",
    "        self.perdas_treino.clear()\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Atualiza curva de aprendizado validação\n",
    "        perda_media = torch.stack(self.perdas_val).mean()\n",
    "        self.curva_aprendizado_val.append(float(perda_media))\n",
    "        self.perdas_val.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCAS = 5\n",
    "treinador = L.Trainer(max_epochs=NUM_EPOCAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = \"fit\" \n",
    "ATRIBUTOS = ['AT']\n",
    "TARGET = ['CO', 'NOX']\n",
    "\n",
    "\n",
    "dm = DataModule()\n",
    "dm.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = len(ATRIBUTOS)\n",
    "num_hidden = 1\n",
    "num_outputs = len(TARGET)\n",
    "#taxa_aprendizado = 0.01\n",
    "\n",
    "modelo = TimeSeriesModel(\n",
    "    num_inputs, num_hidden, num_outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | lstm | LSTM   | 16    \n",
      "1 | fc   | Linear | 4     \n",
      "--------------------------------\n",
      "20        Trainable params\n",
      "0         Non-trainable params\n",
      "20        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65dc8181dec84d3088e74e0cdf390a0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'seq_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\enzo24035\\OneDrive - ILUM ESCOLA DE CIÊNCIA\\Documentos\\Outros\\Estágios\\Enzo-Januzzi---Redes-Neurais\\Projeto\\Modelos.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m treinador\u001b[39m.\u001b[39;49mfit(modelo, dm)\n",
      "File \u001b[1;32mc:\\venv\\ilumpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m TrainerStatus\u001b[39m.\u001b[39mRUNNING\n\u001b[0;32m    543\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 544\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[0;32m    545\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[0;32m    546\u001b[0m )\n",
      "File \u001b[1;32mc:\\venv\\ilumpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 44\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32mc:\\venv\\ilumpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    574\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    575\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[0;32m    576\u001b[0m     ckpt_path,\n\u001b[0;32m    577\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    578\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    579\u001b[0m )\n\u001b[1;32m--> 580\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[0;32m    582\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[0;32m    583\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\venv\\ilumpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:989\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    986\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    987\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    988\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 989\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[0;32m    991\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    992\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    993\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    994\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\venv\\ilumpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1033\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[0;32m   1032\u001b[0m     \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1033\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[0;32m   1034\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m   1035\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mrun()\n",
      "File \u001b[1;32mc:\\venv\\ilumpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1062\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1059\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1061\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[1;32m-> 1062\u001b[0m val_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[0;32m   1064\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1066\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
      "File \u001b[1;32mc:\\venv\\ilumpy\\Lib\\site-packages\\lightning\\pytorch\\loops\\utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     context_manager \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mno_grad\n\u001b[0;32m    181\u001b[0m \u001b[39mwith\u001b[39;00m context_manager():\n\u001b[1;32m--> 182\u001b[0m     \u001b[39mreturn\u001b[39;00m loop_run(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\venv\\ilumpy\\Lib\\site-packages\\lightning\\pytorch\\loops\\evaluation_loop.py:109\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[39m@_no_grad_context\u001b[39m\n\u001b[0;32m    108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[_OUT_DICT]:\n\u001b[1;32m--> 109\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetup_data()\n\u001b[0;32m    110\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskip:\n\u001b[0;32m    111\u001b[0m         \u001b[39mreturn\u001b[39;00m []\n",
      "File \u001b[1;32mc:\\venv\\ilumpy\\Lib\\site-packages\\lightning\\pytorch\\loops\\evaluation_loop.py:165\u001b[0m, in \u001b[0;36m_EvaluationLoop.setup_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    163\u001b[0m stage \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stage\n\u001b[0;32m    164\u001b[0m source \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_source\n\u001b[1;32m--> 165\u001b[0m dataloaders \u001b[39m=\u001b[39m _request_dataloader(source)\n\u001b[0;32m    166\u001b[0m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mbarrier(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mstage\u001b[39m.\u001b[39mdataloader_prefix\u001b[39m}\u001b[39;00m\u001b[39m_dataloader()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    168\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(dataloaders, CombinedLoader):\n",
      "File \u001b[1;32mc:\\venv\\ilumpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:342\u001b[0m, in \u001b[0;36m_request_dataloader\u001b[1;34m(data_source)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Requests a dataloader by calling dataloader hooks corresponding to the given stage.\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \n\u001b[0;32m    333\u001b[0m \u001b[39mReturns:\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39m    The requested dataloader\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[39mwith\u001b[39;00m _replace_dunder_methods(DataLoader, \u001b[39m\"\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m\"\u001b[39m), _replace_dunder_methods(BatchSampler):\n\u001b[0;32m    338\u001b[0m     \u001b[39m# under this context manager, the arguments passed to `DataLoader.__init__` will be captured and saved as\u001b[39;00m\n\u001b[0;32m    339\u001b[0m     \u001b[39m# attributes on the instance in case the dataloader needs to be re-instantiated later by Lightning.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m     \u001b[39m# Also, it records all attribute setting and deletion using patched `__setattr__` and `__delattr__`\u001b[39;00m\n\u001b[0;32m    341\u001b[0m     \u001b[39m# methods so that the re-instantiated object is as close to the original as possible.\u001b[39;00m\n\u001b[1;32m--> 342\u001b[0m     \u001b[39mreturn\u001b[39;00m data_source\u001b[39m.\u001b[39;49mdataloader()\n",
      "File \u001b[1;32mc:\\venv\\ilumpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:309\u001b[0m, in \u001b[0;36m_DataLoaderSource.dataloader\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minstance, pl\u001b[39m.\u001b[39mLightningDataModule):\n\u001b[0;32m    308\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minstance\u001b[39m.\u001b[39mtrainer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 309\u001b[0m     \u001b[39mreturn\u001b[39;00m call\u001b[39m.\u001b[39;49m_call_lightning_datamodule_hook(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minstance\u001b[39m.\u001b[39;49mtrainer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[0;32m    310\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minstance \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minstance\n",
      "File \u001b[1;32mc:\\venv\\ilumpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:179\u001b[0m, in \u001b[0;36m_call_lightning_datamodule_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(fn):\n\u001b[0;32m    178\u001b[0m     \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningDataModule]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mdatamodule\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 179\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    180\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\enzo24035\\OneDrive - ILUM ESCOLA DE CIÊNCIA\\Documentos\\Outros\\Estágios\\Enzo-Januzzi---Redes-Neurais\\Projeto\\Modelos.ipynb Cell 21\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X36sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mval_dataloader\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X36sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m     dataset_val \u001b[39m=\u001b[39m TempDataset(seq_val)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X36sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m     dataloader_val \u001b[39m=\u001b[39m DataLoader(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X36sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m         dataset_val, batch_size\u001b[39m=\u001b[39mTAMANHO_LOTE, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzo24035/OneDrive%20-%20ILUM%20ESCOLA%20DE%20CI%C3%8ANCIA/Documentos/Outros/Est%C3%A1gios/Enzo-Januzzi---Redes-Neurais/Projeto/Modelos.ipynb#X36sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m dataloader_val\n",
      "\u001b[1;31mNameError\u001b[0m: name 'seq_val' is not defined"
     ]
    }
   ],
   "source": [
    "treinador.fit(modelo, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_treino = modelo.curva_aprendizado_treino\n",
    "ca_val = modelo.curva_aprendizado_val\n",
    "\n",
    "sns.lineplot(ca_treino, label=\"Treino\")\n",
    "eixo = sns.lineplot(ca_val, label=\"Validação\")\n",
    "\n",
    "eixo.set_xlim(left=0)\n",
    "\n",
    "eixo.set_title(\"Curva de aprendizado\")\n",
    "eixo.set_xlabel(\"Época\")\n",
    "eixo.set_ylabel(\"Loss\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1]\n",
    "\n",
    "[2]\n",
    "\n",
    "[3]\n",
    "\n",
    "[4]\n",
    "\n",
    "[] Biblioteca do normalizador padrão - scikit learn: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "\n",
    "[] David Menotti, aula sobre MLP: https://www.inf.ufpr.br/menotti/ci171-182/slides/ci171-classMLP.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy",
   "language": "python",
   "name": "ilumpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
